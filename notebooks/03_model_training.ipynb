{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-30T11:32:02.924243Z",
     "start_time": "2025-08-30T11:32:02.758435Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if a GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:32:32.280055Z",
     "start_time": "2025-08-30T11:32:32.266296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_final = np.load(\"../processed/X_train_final.npy\")\n",
    "X_test_final = np.load(\"../processed/X_test_final.npy\")\n",
    "y_train_df = pd.read_csv(\"../processed/y_train.csv\")\n",
    "y_train = y_train_df[\"time_taken_minutes\"].values\n",
    "\n",
    "print(f\"Shape of training features: {X_train_final.shape}\")\n",
    "print(f\"Shape of training target: {y_train.shape}\")"
   ],
   "id": "a4abb983011640d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features: (45593, 25)\n",
      "Shape of training target: (45593,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:34:47.729329Z",
     "start_time": "2025-08-30T11:34:47.725722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeliveryTimeDataset(Dataset):\n",
    "\tdef __init__(self, features, targets=None):\n",
    "\t\tself.features = torch.tensor(features, dtype=torch.float32)\n",
    "\t\tself.targets = torch.tensor(targets, dtype=torch.float32).view(-1, 1) if targets is not None else None\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.features)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tif self.targets is not None:\n",
    "\t\t\treturn self.features[idx], self.targets[idx]\n",
    "\t\telse:\n",
    "\t\t\treturn self.features[idx]"
   ],
   "id": "8f3d86098bbd1f4c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:36:21.912423Z",
     "start_time": "2025-08-30T11:36:21.908303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = DeliveryTimeDataset(X_train_final, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=4)"
   ],
   "id": "c6ad2fd82972a40a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:36:29.559382Z",
     "start_time": "2025-08-30T11:36:29.499166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inspecting a batch of data\n",
    "features_batch, targets_batch = next(iter(train_loader))\n",
    "print(f\"Shape of a feature batch: {features_batch.shape}\")\n",
    "print(f\"Shape of a target batch: {targets_batch.shape}\")"
   ],
   "id": "27bf2141d5d40170",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a feature batch: torch.Size([64, 25])\n",
      "Shape of a target batch: torch.Size([64, 1])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:38:34.751537Z",
     "start_time": "2025-08-30T11:38:34.748907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeliveryTimeModel(nn.Module):\n",
    "\tdef __init__(self, input_dim):\n",
    "\t\tsuper(DeliveryTimeModel, self).__init__()\n",
    "\n",
    "\t\tself.network = nn.Sequential(\n",
    "\t\t\tnn.Linear(input_dim, 128),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(0.3), # Dropout for regularization\n",
    "\n",
    "\t\t\tnn.Linear(128, 64),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(0.3),\n",
    "\n",
    "\t\t\tnn.Linear(64, 32),\n",
    "\t\t\tnn.ReLU(),\n",
    "\n",
    "\t\t\tnn.Linear(32, 1) # 1 neuron for regression output\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.network(x)"
   ],
   "id": "e11b0362e9d5cddb",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:39:49.920759Z",
     "start_time": "2025-08-30T11:39:49.916446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_size = X_train_final.shape[1]\n",
    "model = DeliveryTimeModel(input_dim=input_size).to(device)\n",
    "model"
   ],
   "id": "b4521894a4d97ca3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeliveryTimeModel(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=25, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:41:36.772586Z",
     "start_time": "2025-08-30T11:41:34.236157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0005)"
   ],
   "id": "f8b47143e218e34e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:45:21.872164Z",
     "start_time": "2025-08-30T11:44:09.798050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training loop\n",
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "\tmodel.train()\n",
    "\n",
    "\trunning_loss = 0.0\n",
    "\tfor i, (features, targets) in enumerate(train_loader):\n",
    "\t\tfeatures, targets = features.to(device), targets.to(device)\n",
    "\n",
    "\t\tpredictions = model(features)\n",
    "\t\tloss = criterion(predictions, targets)\n",
    "\n",
    "\t\toptimizer.zero_grad() # Since we have loss already, we can clear gradients\n",
    "\t\tloss.backward() # Backpropagation\n",
    "\t\toptimizer.step() # Update weights\n",
    "\n",
    "\t\trunning_loss += loss.item()\n",
    "\n",
    "\tepoch_loss = running_loss / len(train_loader)\n",
    "\tprint(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print(\"Finished training.\")"
   ],
   "id": "af26b974cea57875",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 90.7885\n",
      "Epoch [2/50], Loss: 43.6608\n",
      "Epoch [3/50], Loss: 40.4026\n",
      "Epoch [4/50], Loss: 38.4261\n",
      "Epoch [5/50], Loss: 36.4508\n",
      "Epoch [6/50], Loss: 34.8755\n",
      "Epoch [7/50], Loss: 34.0279\n",
      "Epoch [8/50], Loss: 32.9314\n",
      "Epoch [9/50], Loss: 32.3844\n",
      "Epoch [10/50], Loss: 31.9744\n",
      "Epoch [11/50], Loss: 31.4546\n",
      "Epoch [12/50], Loss: 30.7494\n",
      "Epoch [13/50], Loss: 30.4815\n",
      "Epoch [14/50], Loss: 30.1585\n",
      "Epoch [15/50], Loss: 29.5894\n",
      "Epoch [16/50], Loss: 29.4186\n",
      "Epoch [17/50], Loss: 28.9220\n",
      "Epoch [18/50], Loss: 28.8814\n",
      "Epoch [19/50], Loss: 28.5883\n",
      "Epoch [20/50], Loss: 28.3768\n",
      "Epoch [21/50], Loss: 28.3908\n",
      "Epoch [22/50], Loss: 28.4344\n",
      "Epoch [23/50], Loss: 27.9184\n",
      "Epoch [24/50], Loss: 28.0651\n",
      "Epoch [25/50], Loss: 27.6314\n",
      "Epoch [26/50], Loss: 27.2361\n",
      "Epoch [27/50], Loss: 27.5281\n",
      "Epoch [28/50], Loss: 27.1668\n",
      "Epoch [29/50], Loss: 26.9722\n",
      "Epoch [30/50], Loss: 26.4862\n",
      "Epoch [31/50], Loss: 26.0432\n",
      "Epoch [32/50], Loss: 25.2987\n",
      "Epoch [33/50], Loss: 24.9296\n",
      "Epoch [34/50], Loss: 24.6173\n",
      "Epoch [35/50], Loss: 24.1140\n",
      "Epoch [36/50], Loss: 23.8502\n",
      "Epoch [37/50], Loss: 23.1876\n",
      "Epoch [38/50], Loss: 22.7395\n",
      "Epoch [39/50], Loss: 22.2549\n",
      "Epoch [40/50], Loss: 21.8476\n",
      "Epoch [41/50], Loss: 21.5356\n",
      "Epoch [42/50], Loss: 21.4762\n",
      "Epoch [43/50], Loss: 21.0921\n",
      "Epoch [44/50], Loss: 20.7872\n",
      "Epoch [45/50], Loss: 20.6716\n",
      "Epoch [46/50], Loss: 20.5274\n",
      "Epoch [47/50], Loss: 20.1278\n",
      "Epoch [48/50], Loss: 20.1208\n",
      "Epoch [49/50], Loss: 19.9552\n",
      "Epoch [50/50], Loss: 19.8291\n",
      "Finished training.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:46:21.667175Z",
     "start_time": "2025-08-30T11:46:20.883902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing\n",
    "model.eval() # Set to evaluation mode\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\tfor features, targets in train_loader:\n",
    "\t\tfeatures, targets = features.to(device), targets.to(device)\n",
    "\t\tpredictions = model(features)\n",
    "\n",
    "\t\tall_predictions.extend(predictions.cpu().numpy())\n",
    "\t\tall_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# Flatten the lists\n",
    "all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "rmse = np.sqrt(np.mean((all_predictions - all_targets) ** 2))\n",
    "print(f\"Training RMSE: {rmse:.4f} minutes\")\n"
   ],
   "id": "35424787d820e383",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 4.2415 minutes\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-30T11:51:25.378317Z",
     "start_time": "2025-08-30T11:51:25.373257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inspecting the RMSE against some basic statistics of the target variable\n",
    "min_time = np.min(y_train)\n",
    "max_time = np.max(y_train)\n",
    "mode = pd.Series(y_train).mode()[0]\n",
    "mean_time = np.mean(y_train)\n",
    "median_time = np.median(y_train)\n",
    "print(f\"Min time: {min_time}, Max time: {max_time}, Mode: {mode}, Mean: {mean_time}, Median: {median_time}\")\n",
    "\n",
    "baseline_rmse = y_train.std()\n",
    "print(f\"Standard Deviation (Baseline RMSE): {baseline_rmse:.4f} minutes\")\n",
    "improvement = (baseline_rmse - rmse) / baseline_rmse * 100\n",
    "print(f\"Improvement over baseline: {improvement:.2f}%\")"
   ],
   "id": "3b51a814451eb390",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min time: 10.0, Max time: 54.0, Mode: 26.0, Mean: 26.29460662821047, Median: 26.0\n",
      "Standard Deviation (Baseline RMSE): 9.3837 minutes\n",
      "Improvement over baseline: 54.80%\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "An improvement of around 40% over the baseline is quite significant, indicating that the model is effectively capturing patterns in the data to predict delivery times more accurately than a naive approach. This suggests that our feature engineering and model architecture choices are beneficial for this regression task.\n",
    "\n",
    "Things learned:\n",
    "- How to prepare data and a preprocessing pipeline using pandas, numpy and sklearn.\n",
    "- How to load data with PyTorch DataLoader.\n",
    "- How to build a feedforward neural network for regression using PyTorch.\n",
    "- How to train and evaluate the model, including calculating RMSE and comparing it to a baseline\n",
    "- How to evaluate time and location data for feature engineering."
   ],
   "id": "8cc862ee6ede9fc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
